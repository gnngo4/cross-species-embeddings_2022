{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c273ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import tempfile\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "surfaces = dict()\n",
    "surfaces['human_lh'] = \"/mnt/WD10TB/datasets/data_view_crossspecies/human/surfaces/S1200.L.very_inflated_MSMAll.10k_fs_LR.surf.gii\"\n",
    "surfaces['human_rh'] = \"/mnt/WD10TB/datasets/data_view_crossspecies/human/surfaces/S1200.R.very_inflated_MSMAll.10k_fs_LR.surf.gii\"\n",
    "surfaces['marmoset_lh'] = \"/mnt/WD10TB/datasets/data_view_crossspecies/marmoset/surfaces/surfFS.lh.pial.inflated.10k.surf.gii\"\n",
    "surfaces['marmoset_rh'] = \"/mnt/WD10TB/datasets/data_view_crossspecies/marmoset/surfaces/surfFS.rh.pial.inflated.10k.surf.gii\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa184264",
   "metadata": {},
   "source": [
    "# Convert 10k surfaces to 32k surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ed62d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_10k_to_32k(species,dscalar_10k):\n",
    "    \n",
    "    \"\"\"\n",
    "    INPUTS into wb_command -cifti-resample\n",
    "    \"\"\"\n",
    "    dscalar_32k = dscalar_10k.replace('dscalar.nii','32k.dscalar.nii')\n",
    "    if species == \"marmoset\":\n",
    "        template = \"/mnt/WD10TB/templates/Marmoset_Brain_Mappping_v3.0.1/Marmoset_Brain_Mappping_v3.0.1/MBM_v3.0.1/derivatives/surfFS.MBM_cortex_vPaxinos.dscalar.nii\"\n",
    "        lh_sphere_10k = \"/mnt/WD10TB/templates/Marmoset_Brain_Mappping_v3.0.1/Marmoset_Brain_Mappping_v3.0.1/MBM_v3.0.1/derivatives/10k/lh.sphere.10k.surf.gii\"\n",
    "        lh_sphere_32k = \"/mnt/WD10TB/templates/Marmoset_Brain_Mappping_v3.0.1/Marmoset_Brain_Mappping_v3.0.1/MBM_v3.0.1/derivatives/10k/intermediate/surfFS.lh.sphere.match.surf.gii\"\n",
    "        lh_mid_10k = \"/mnt/WD10TB/templates/Marmoset_Brain_Mappping_v3.0.1/Marmoset_Brain_Mappping_v3.0.1/MBM_v3.0.1/derivatives/10k/surfFS.lh.graymid.10k.surf.gii\"\n",
    "        lh_mid_32k = \"/mnt/WD10TB/templates/Marmoset_Brain_Mappping_v3.0.1/Marmoset_Brain_Mappping_v3.0.1/MBM_v3.0.1/surfFS.lh.graymid.surf.gii\"\n",
    "        rh_sphere_10k = \"/mnt/WD10TB/templates/Marmoset_Brain_Mappping_v3.0.1/Marmoset_Brain_Mappping_v3.0.1/MBM_v3.0.1/derivatives/10k/rh.sphere.10k.surf.gii\"\n",
    "        rh_sphere_32k = \"/mnt/WD10TB/templates/Marmoset_Brain_Mappping_v3.0.1/Marmoset_Brain_Mappping_v3.0.1/MBM_v3.0.1/derivatives/10k/intermediate/surfFS.rh.sphere.match.surf.gii\"\n",
    "        rh_mid_10k = \"/mnt/WD10TB/templates/Marmoset_Brain_Mappping_v3.0.1/Marmoset_Brain_Mappping_v3.0.1/MBM_v3.0.1/derivatives/10k/surfFS.rh.graymid.10k.surf.gii\"\n",
    "        rh_mid_32k = \"/mnt/WD10TB/templates/Marmoset_Brain_Mappping_v3.0.1/Marmoset_Brain_Mappping_v3.0.1/MBM_v3.0.1/surfFS.rh.graymid.surf.gii\"\n",
    "    if species == \"human\":\n",
    "        template = \"/mnt/WD10TB/templates/surfaces/S1200.MyelinMap_BC_MSMAll.32k_fs_LR.dscalar.nii\"\n",
    "        lh_sphere_10k = \"/mnt/WD10TB/templates/standard_mesh_atlases/L.sphere.10k_fs_LR.surf.gii\"\n",
    "        lh_sphere_32k = \"/mnt/WD10TB/templates/standard_mesh_atlases/L.sphere.32k_fs_LR.surf.gii\"\n",
    "        lh_mid_10k = \"/mnt/WD10TB/templates/surfaces/S1200.L.midthickness_MSMAll.10k_fs_LR.surf.gii\"\n",
    "        lh_mid_32k = \"/mnt/WD10TB/templates/surfaces/S1200.L.midthickness_MSMAll.32k_fs_LR.surf.gii\"\n",
    "        rh_sphere_10k = \"/mnt/WD10TB/templates/standard_mesh_atlases/R.sphere.10k_fs_LR.surf.gii\"\n",
    "        rh_sphere_32k = \"/mnt/WD10TB/templates/standard_mesh_atlases/R.sphere.32k_fs_LR.surf.gii\"\n",
    "        rh_mid_10k = \"/mnt/WD10TB/templates/surfaces/S1200.R.midthickness_MSMAll.10k_fs_LR.surf.gii\"\n",
    "        rh_mid_32k = \"/mnt/WD10TB/templates/surfaces/S1200.R.midthickness_MSMAll.32k_fs_LR.surf.gii\"\n",
    "\n",
    "    cmd = f\"wb_command -cifti-resample {dscalar_10k} COLUMN {template} COLUMN ADAP_BARY_AREA CUBIC {dscalar_32k} -left-spheres {lh_sphere_10k} {lh_sphere_32k} -left-area-surfs {lh_mid_10k} {lh_mid_32k} -right-spheres {rh_sphere_10k} {rh_sphere_32k} -right-area-surfs {rh_mid_10k} {rh_mid_32k}\"\n",
    "    os.system(cmd)\n",
    "    \n",
    "    return dscalar_32k\n",
    "\n",
    "dir_10k = \"/home/geoff/Desktop/Projects/InProgress/ConnectomeEmbeddings/notebooks/notebook_data/2_DMN_nodes/visualization\"\n",
    "for species in ['human','marmoset']:\n",
    "    dir_10k_ = os.path.join(dir_10k,species)\n",
    "    for dscalar in [os.path.join(dir_10k_,y) for y in os.listdir(dir_10k_) if 'dscalar.nii' in y]:\n",
    "        convert_10k_to_32k(species,dscalar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bddbac3",
   "metadata": {},
   "source": [
    "# Crop screen captures of wb_view surfaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7ddc2df7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-64c88147ad90>:22: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'for species in [\\'human\\',\\'marmoset\\']:\\n    screencap_dir = f\"./wb_view_screencap/{species}/similar_gradient_profiles\"\\n    for f in os.listdir(screencap_dir):\\n        crop_wb_view_screencap(species,os.path.join(screencap_dir,f))'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def crop_wb_view_screencap(species,im,view_flag=False):\n",
    "    \n",
    "    import PIL\n",
    "    from PIL import Image, ImageChops\n",
    "    i = PIL.Image.open(im)\n",
    "    width,height = i.size\n",
    "\n",
    "    if species == 'marmoset':\n",
    "        # Setting the points for cropped image\n",
    "        left = 750\n",
    "        top = height*.32\n",
    "        right = 2500\n",
    "        bottom = height*.94\n",
    "        # Rearrange left and right hemisphere flatmaps\n",
    "        i = i.crop((left, top, right, bottom))\n",
    "        i_l = i.crop((0,0,i.size[0]*.5,i.size[1])).rotate(245,fillcolor=(255,255,255,255))\n",
    "        i_r = i.crop((i.size[0]*.5,0,i.size[0],i.size[1])).rotate(-65,fillcolor=(255,255,255,255))\n",
    "        i_r = ImageChops.offset(i_r, -60, -45)\n",
    "        imgs    = [ i_l, i_r ]\n",
    "        # pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "        min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "        imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "        # save that beautiful picture\n",
    "        imgs_comb = PIL.Image.fromarray(imgs_comb)\n",
    "        imgs_comb = imgs_comb.crop((0,100,1700,820))\n",
    "        imgs_comb.save(im.replace('.png','_cropped.png'))\n",
    "        if view_flag:\n",
    "            plt.imshow(imgs_comb)\n",
    "            \n",
    "    if species == 'human':\n",
    "        # Setting the points for cropped image\n",
    "        left = 750\n",
    "        top = height*.32\n",
    "        right = 2500\n",
    "        bottom = height*.94\n",
    "        # Rearrange left and right hemisphere flatmaps\n",
    "        i = i.crop((837, 550, 2560, 1250))\n",
    "        i.save(im.replace('.png','_cropped.png'))\n",
    "        if view_flag:\n",
    "            plt.imshow(i)\n",
    "\n",
    "marmoset_screencap_dir = './wb_view_screencap/marmoset'\n",
    "#crop_wb_view_screencap('marmoset',os.path.join(marmoset_screencap_dir,'1.png'))\n",
    "#crop_wb_view_screencap('marmoset',os.path.join(marmoset_screencap_dir,'2.png'))\n",
    "for i in ['dlPFC_lh','dlPFC_rh','PCC_lh','PCC_rh','PPC_lh','PPC_rh']:\n",
    "    for j in ['0','0.05','0.10','0.15']:\n",
    "        crop_wb_view_screencap('marmoset',os.path.join(marmoset_screencap_dir,j,f\"{i}.png\"))\n",
    "\n",
    "human_screencap_dir = './wb_view_screencap/human'\n",
    "#crop_wb_view_screencap('human',os.path.join(human_screencap_dir,'1.png'))\n",
    "#crop_wb_view_screencap('human',os.path.join(human_screencap_dir,'2.png'))\n",
    "for i in ['dlPFC_lh','dlPFC_rh','PCC_lh','PCC_rh','PPC_lh','PPC_rh']:\n",
    "    for j in ['0','0.1','0.2','0.3']:\n",
    "        crop_wb_view_screencap('human',os.path.join(human_screencap_dir,j,f\"{i}.png\"))\n",
    "\n",
    "\"\"\"for species in ['human','marmoset']:\n",
    "    screencap_dir = f\"./wb_view_screencap/{species}/similar_gradient_profiles\"\n",
    "    for f in os.listdir(screencap_dir):\n",
    "        crop_wb_view_screencap(species,os.path.join(screencap_dir,f))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d462dc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-64c88147ad90>:22: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n"
     ]
    }
   ],
   "source": [
    "marmoset_screencap_dir='./wb_view_screencap/marmoset/mPFC'\n",
    "for i in ['A10_lh','A10_rh','A32_lh','A32_rh','A32V_lh','A32V_rh','marmoset_joint_gradient_3']:\n",
    "    crop_wb_view_screencap('marmoset',os.path.join(marmoset_screencap_dir,f\"{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eda07a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-3-64c88147ad90>:22: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n"
     ]
    }
   ],
   "source": [
    "marmoset_screencap_dir='./wb_view_screencap/marmoset/mPFC'\n",
    "for i in ['A10_lh','A10_rh','A32_lh','A32_rh','A32V_lh','A32V_rh','marmoset_joint_gradient_3']:\n",
    "    crop_wb_view_screencap('marmoset',os.path.join(marmoset_screencap_dir,f\"{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "689c1ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "marmoset_screencap_dir='./wb_view_screencap/human/mPFC'\n",
    "for i in ['human_joint_gradient']:\n",
    "    crop_wb_view_screencap('human',os.path.join(marmoset_screencap_dir,f\"{i}.png\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20696845",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
